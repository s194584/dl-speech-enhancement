{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook for project results in 02456 Deep Learning\n",
    "This notebook will load our final model and will perform inference on 6 randomly selected clean-noise pairs from the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, the model and audio files will be downloaded from Google Drive. Note that these will be stored locally in the folder \"notebook_files\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Create notebook folder for temporary files\n",
    "directory = \"notebook_files_\\\\\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Download folder with model and example audio files\n",
    "url = \"https://drive.google.com/drive/folders/1jRPZWRAQE2PKvnc5zpxK1r09J7OZjWsR?usp=sharing\"\n",
    "gdown.download_folder(url,output=directory, quiet=True, use_cookies=False)\n",
    "1\n",
    "\n",
    "directory = \"notebook_files_\\\\notebook_files\\\\\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:41:44.478523Z",
     "end_time": "2023-12-21T08:43:02.276573Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.autoencoder_without_PQC.AudioDec import Generator as GeneratorAudioDec\n",
    "\n",
    "config = {\n",
    "    \"input_channels\": 1,\n",
    "    \"output_channels\": 1,\n",
    "    \"encode_channels\": 32,\n",
    "    \"decode_channels\": 32,\n",
    "    \"bias\": True,\n",
    "    \"enc_ratios\": [2, 4, 8, 16],\n",
    "    \"dec_ratios\": [16, 8, 4, 2],\n",
    "    \"enc_strides\": [3, 4, 5, 5],\n",
    "    \"dec_strides\": [5, 5, 4, 3],\n",
    "    \"mode\": 'causal'\n",
    "}\n",
    "\n",
    "model: dict[str, torch.nn.Module] = {}\n",
    "model[\"generator\"] = GeneratorAudioDec(**config)\n",
    "state_dict = torch.load(directory+\"model.pkl\", map_location=\"cpu\")\n",
    "model[\"generator\"].load_state_dict(state_dict)\n",
    "\n",
    "SAMPLE_RATE = 24000\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:43:02.284574Z",
     "end_time": "2023-12-21T08:43:02.609398Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import glob\n",
    "from dataloader.data_utils import add_noise\n",
    "\n",
    "\n",
    "def get_file_paths(prefix):\n",
    "    return glob.glob(directory+prefix+\"*\"+\".wav\")\n",
    "clean_file_paths = get_file_paths(\"clean\")\n",
    "noise_file_paths = get_file_paths(\"noise\")\n",
    "\n",
    "def load_samples(file_paths):\n",
    "    samples = []\n",
    "    for file_path in file_paths:\n",
    "        audio, original_sample_rate = torchaudio.load(file_path, backend=\"soundfile\")\n",
    "        # Down sample to fit trained model\n",
    "        audio = torchaudio.functional.resample(audio, original_sample_rate, SAMPLE_RATE)\n",
    "        samples.append(audio)\n",
    "    return  samples\n",
    "\n",
    "\n",
    "clean_samples = load_samples(clean_file_paths)\n",
    "noise_samples = load_samples(noise_file_paths)\n",
    "\n",
    "for i, (clean_sample,noise_sample) in enumerate(zip(clean_samples,noise_samples)):\n",
    "    if clean_sample.shape[1] > noise_sample.shape[1]:\n",
    "        clean_samples[i] = clean_sample[:, :noise_sample.shape[1]]\n",
    "    else:\n",
    "        noise_samples[i] = noise_sample[:, :clean_sample.shape[1]]\n",
    "\n",
    "\n",
    "# Storing trimmed noise files\n",
    "for i, noise_sample in enumerate(noise_samples):\n",
    "    # (C,L) -> (B,C,L)\n",
    "    file_path = directory+f\"noise{i+1}.wav\"\n",
    "    torchaudio.save(file_path,noise_sample,SAMPLE_RATE)\n",
    "    noise_file_paths[i]=file_path\n",
    "\n",
    "# Mixing at SNR of 15\n",
    "mixed_samples = [add_noise(speech,noise,torch.tensor(15)) for speech,noise in zip(clean_samples,noise_samples)]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:43:02.618399Z",
     "end_time": "2023-12-21T08:43:02.893421Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "predictions = []\n",
    "pred_file_paths = []\n",
    "mixed_file_paths = []\n",
    "for i, mixed_sample in enumerate(mixed_samples):\n",
    "    # (C,L) -> (B,C,L)\n",
    "    file_path = directory+f\"mixed{i+1}.wav\"\n",
    "    torchaudio.save(file_path,mixed_sample,SAMPLE_RATE)\n",
    "    mixed_file_paths.append(file_path)\n",
    "\n",
    "\n",
    "    mixed_sample = mixed_sample.unsqueeze(0)\n",
    "    pred = model[\"generator\"](mixed_sample)\n",
    "    pred = pred.squeeze(0).detach()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    file_path = directory+f\"prediction{i+1}.wav\"\n",
    "    torchaudio.save(file_path,pred,SAMPLE_RATE)\n",
    "    pred_file_paths.append(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:43:02.897419Z",
     "end_time": "2023-12-21T08:43:07.708912Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Showcase\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean1.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean1.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise1.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise1.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed1.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed1.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction1.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction1.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean2.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean2.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise2.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise2.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed2.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed2.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction2.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction2.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean3.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean3.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise3.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise3.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed3.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed3.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction3.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction3.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean4.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean4.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise4.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise4.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed4.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed4.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction4.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction4.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean5.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean5.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise5.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise5.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed5.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed5.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction5.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction5.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <h2>Input</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>clean6.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\clean6.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>noise6.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\noise6.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    <h2>Inference</h2>\n    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n        \n    <div>\n        <p>mixed6.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\mixed6.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n        \n    <div>\n        <p>prediction6.wav</p>\n        <audio controls>\n            <source src=\"notebook_files_\\notebook_files\\prediction6.wav\" type=\"audio/wav\">\n        </audio>\n    </div>\n    \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython,time\n",
    "from IPython.display import Audio, HTML, Markdown, display\n",
    "\n",
    "\n",
    "def html_label_audio(audio_path):\n",
    "    # print(audio_path)\n",
    "    sep = \"notebook_files\\\\\"\n",
    "    return f\"\"\"\n",
    "    <div>\n",
    "        <p>{audio_path.split(sep)[1]}</p>\n",
    "        <audio controls>\n",
    "            <source src=\"{audio_path}\" type=\"audio/wav\">\n",
    "        </audio>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "def html_wrap_cells(cells):\n",
    "    connector = \"\\n\"\n",
    "    return f\"\"\"\n",
    "    <h2>Input</h2>\n",
    "    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n",
    "        {cells[0]}\n",
    "        {cells[1]}\n",
    "    </div>\n",
    "    <h2>Inference</h2>\n",
    "    <div style=\"display: flex;flex:50%; align-items: center; justify-content: space-around;\">\n",
    "        {cells[2]}\n",
    "        {cells[3]}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "for i, sample in enumerate(clean_samples):\n",
    "    clean_html = html_label_audio(clean_file_paths[i])\n",
    "    noise_html = html_label_audio(noise_file_paths[i])\n",
    "    mixed_html = html_label_audio(mixed_file_paths[i])\n",
    "    pred_html = html_label_audio(pred_file_paths[i])\n",
    "\n",
    "    display(HTML(data=html_wrap_cells([clean_html,noise_html,mixed_html,pred_html])))\n",
    "    time.sleep(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:43:07.709904Z",
     "end_time": "2023-12-21T08:43:13.778707Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
