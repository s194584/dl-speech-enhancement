{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook for project results in 02456 Deep Learning\n",
    "This notebook will load our final model and will perform inference on 6 randomly selected clean-noise pairs from the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, the model and audio files will be downloaded from Google Drive. Note that these will be stored locally in the folder \"notebook_files\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1lSWdYqXM4VbwwXGg8Xj0qVxKvPYCLjoq \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "# Create notebook folder for temporary files\n",
    "directory = \"notebook_files/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "url = \"https://drive.google.com/drive/folders/1jRPZWRAQE2PKvnc5zpxK1r09J7OZjWsR?usp=drive_link\"\n",
    "gdown.download_folder(url,output=directory, quiet=True, use_cookies=False)\n",
    "1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T18:25:30.584549Z",
     "end_time": "2023-12-20T18:25:39.155267Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models.autoencoder_without_PQC.AudioDec import Generator as GeneratorAudioDec\n",
    "\n",
    "config = {\n",
    "    \"input_channels\": 1,\n",
    "    \"output_channels\": 1,\n",
    "    \"encode_channels\": 32,\n",
    "    \"decode_channels\": 32,\n",
    "    \"bias\": True,\n",
    "    \"enc_ratios\": [2, 4, 8, 16],\n",
    "    \"dec_ratios\": [16, 8, 4, 2],\n",
    "    \"enc_strides\": [3, 4, 5, 5],\n",
    "    \"dec_strides\": [5, 5, 4, 3],\n",
    "    \"mode\": 'causal'\n",
    "}\n",
    "\n",
    "model: dict[str, torch.nn.Module] = {}\n",
    "model[\"generator\"] = GeneratorAudioDec(**config)\n",
    "state_dict = torch.load(\"notebook_files/model.pkl\", map_location=\"cpu\")\n",
    "model[\"generator\"].load_state_dict(state_dict)\n",
    "\n",
    "SAMPLE_RATE = 24000\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T18:23:38.585021Z",
     "end_time": "2023-12-20T18:23:38.691060Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import glob\n",
    "from dataloader.data_utils import add_noise\n",
    "\n",
    "\n",
    "def get_file_paths(prefix):\n",
    "    return glob.glob(directory+prefix+\"*\"+\".wav\")\n",
    "clean_file_paths = get_file_paths(\"clean\")\n",
    "noise_file_paths = get_file_paths(\"noise\")\n",
    "\n",
    "def load_samples(file_paths):\n",
    "    samples = []\n",
    "    for file_path in file_paths:\n",
    "        audio, _ = torchaudio.load(file_path, backend=\"soundfile\")\n",
    "        samples.append(audio)\n",
    "    return  samples\n",
    "\n",
    "\n",
    "clean_samples = load_samples(clean_file_paths)\n",
    "noise_samples = load_samples(noise_file_paths)\n",
    "\n",
    "# TODO - Down-sample\n",
    "\n",
    "for i, (clean_sample,noise_sample) in enumerate(zip(clean_samples,noise_samples)):\n",
    "    if clean_sample.shape[1] > noise_sample.shape[1]:\n",
    "        clean_samples[i] = clean_sample[:, :noise_sample.shape[1]]\n",
    "    else:\n",
    "        noise_samples[i] = noise_sample[:, :clean_sample.shape[1]]\n",
    "\n",
    "mixed_samples = [add_noise(speech,noise,torch.tensor(15)) for speech,noise in zip(clean_samples,noise_samples)]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T18:56:24.664530Z",
     "end_time": "2023-12-20T18:56:24.699622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 1500])\n",
      "Trimmed shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a dummy tensor of shape (1, 1500)\n",
    "tensor = torch.rand(1, 1500)\n",
    "\n",
    "# Trim the tensor to shape (1, 1000)\n",
    "trimmed_tensor = tensor[:, :1000]\n",
    "\n",
    "print(\"Original shape:\", tensor.shape)\n",
    "print(\"Trimmed shape:\", trimmed_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T18:56:06.277488Z",
     "end_time": "2023-12-20T18:56:06.292418Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-20T18:23:38.708060Z",
     "end_time": "2023-12-20T18:23:38.726567Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
